{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.datasets import mnist\n",
    "import tensorflow.keras as kb\n",
    "from tensorflow.keras import backend\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "\n",
    "from plotnine import *\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, roc_auc_score\n",
    "\n",
    "from sklearn.linear_model import LinearRegression # Linear Regression Model\n",
    "from sklearn.preprocessing import StandardScaler #Z-score variables\n",
    "\n",
    "from sklearn.model_selection import train_test_split # simple TT split cv\n",
    "from sklearn.model_selection import KFold # k-fold cv\n",
    "from sklearn.model_selection import LeaveOneOut #LOO cv\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Keras Compnents\n",
    "\n",
    "## Model Objects\n",
    "- `Model()`: an object that groups layers together to be trained and to make predictions\n",
    "\n",
    "\n",
    "With `Model()` objects we can either use the **Functional API** to interface with them, or we can subclass the `Model()` object. \n",
    "\n",
    "### Functional API\n",
    "Here, we treat layers as functions that have input tensors and output tensors. Each layer takes in the output from the previous layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 25)]              0         \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 10)                260       \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 5)                 55        \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 2)                 12        \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 330\n",
      "Trainable params: 330\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Functional API building\n",
    "\n",
    "inputs = kb.Input(shape = (25,))\n",
    "\n",
    "x = kb.layers.Dense(10)(inputs)\n",
    "\n",
    "x = kb.layers.Dense(5)(x)\n",
    "\n",
    "x = kb.layers.Dense(2)(x)\n",
    "\n",
    "outputs = kb.layers.Dense(1, activation = tf.nn.sigmoid)(x)\n",
    "\n",
    "model = kb.Model(inputs = inputs, outputs = outputs)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can create a new class that inherits from `Model()`. We won't do this too often in this class, but it is useful to know that it exists. \n",
    "\n",
    "First we create a class that inherets from `kb.Model`, and then we create an `__init__` method that first calls the superclass' `__init__()` and then defines every layer that we need. We want this to happen in the constructor, otherwise the layers might be created more than once (which we do not want).\n",
    "\n",
    "Then we create a `call()` method which basically defines what a forward pass of your model looks like. It takes in the default `self` arugment as well as some input to the model. This looks similar to how we defined things using the Functional API. Then we return the output of the model. \n",
    "\n",
    "Now we can use this subclass to build a model!\n",
    "- We create inputs\n",
    "- We put those inputs into our model object\n",
    "- We put both into a `Model()` object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 25)]              0         \n",
      "                                                                 \n",
      " my_model_9 (MyModel)        (None, 1)                 330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 330\n",
      "Trainable params: 330\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# we won't do this often but its nice to know\n",
    "\n",
    "class MyModel(kb.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        # call init from inhereted class\n",
    "        super().__init__()\n",
    "\n",
    "        # create all layers here so they're only created once\n",
    "        self.layer1 = kb.layers.Dense(10, input_shape = [25])\n",
    "        self.layer2 = kb.layers.Dense(5)\n",
    "        self.layer3 = kb.layers.Dense(2)\n",
    "        self.layer4 = kb.layers.Dense(1, activation = \"sigmoid\")\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        # define what a forward pass looks like\n",
    "        x = self.layer1(inputs)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        return(self.layer4(x))\n",
    "\n",
    "# define input shape\n",
    "inputs = kb.Input(shape = (25,))\n",
    "\n",
    "# create a model using your custom class\n",
    "x = MyModel()(inputs)\n",
    "\n",
    "# shove the inputs and outputs into a model object\n",
    "my_model = kb.Model(inputs = inputs, outputs = x)\n",
    "\n",
    "# show me the model\n",
    "my_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Object\n",
    "\n",
    "- `Sequential()`: an object that groups layers together in a linear stack (less flexible than `Model` but typically all we need)\n",
    "\n",
    "This is what we've done so far (and what we did in CPSC 392). We create a `Sequential()` object and give it a list of layers to add (in order).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 10)                260       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 5)                 55        \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 2)                 12        \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 330\n",
      "Trainable params: 330\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# give Sequential a list of layers\n",
    "my_model = kb.Sequential([\n",
    "    kb.layers.Dense(10, input_shape = [25]),\n",
    "    kb.layers.Dense(5),\n",
    "    kb.layers.Dense(2),\n",
    "    kb.layers.Dense(1, activation = \"sigmoid\")\n",
    "])\n",
    "\n",
    "my_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to add layers dynamically, we can use `.add()` and `.pop()` to add and pop layers on/off our model. This would be useful, for example, if we wanted to loop through a list of values and add layers with those values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_16 (Dense)            (None, 10)                260       \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 5)                 55        \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 2)                 12        \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 330\n",
      "Trainable params: 330\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# use .add() to dynamically add layers\n",
    "my_model = kb.Sequential()\n",
    "my_model.add(kb.layers.Dense(10, input_shape = [25]))\n",
    "my_model.add(kb.layers.Dense(5))\n",
    "my_model.add(kb.layers.Dense(2))\n",
    "my_model.add(kb.layers.Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "my_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Layers\n",
    "Keras has many pre-defined layers that we can use (we'll learn about more of them as we learn about more model structures). For now the important layers are:\n",
    "\n",
    "- `Dense()`: A basic densely connected layer with `units` nodes. Densely connected means that every node in the previous layer is connected to every node in the current layer. \n",
    "- `Activation()`: applies an activation function (defined by the `activation` argument) to the values coming into it. This is largely the same as using the `activation` argument in a `Dense` Layer but is useful when you want to do an operation to the layer output BEFORE applying the activation (e.g. `BatchNormalization`)\n",
    "- `Input()`: A basic layer that defined the input of a model. It tells the model what the initial tensor of data that we expect to come in looks like. The `shape` argument tells the model what a *single sample* of data looks like (not a batch of samples)\n",
    "\n",
    "\n",
    "`Dense` Layers tend to be the basis of most of our Neural Networks, so let's get to know the documentation a little!\n",
    "\n",
    "- **Question** look at the [documentation](https://keras.io/api/layers/core_layers/dense/) for `Dense` layers. If I wanted to NOT have a bias for that layer, how might I tell python that?\n",
    "- **Question** look at the [documentation](https://keras.io/api/layers/core_layers/dense/) for `Dense` layers. If you do not supply a value for `activation` what activation does it use?\n",
    "\n",
    "\n",
    "There are many activation functions (or you can even define your own), let's look at the `activation` documentation and see what's available:\n",
    "\n",
    "- **Question** look at the [documentation](https://keras.io/api/layers/activations/) for `activations`. What basic activation functions are available?\n",
    "- Modify the code below to add a `ReLu` activation to the middle layer (either using the `activation` argument in `Dense()` or by adding an `Activation()` layer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_78 (Dense)            (None, 10)                260       \n",
      "                                                                 \n",
      " dense_79 (Dense)            (None, 5)                 55        \n",
      "                                                                 \n",
      " dense_80 (Dense)            (None, 2)                 12        \n",
      "                                                                 \n",
      " dense_81 (Dense)            (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 330\n",
      "Trainable params: 330\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### YOUR CODE HERE ###\n",
    "activated_model = kb.Sequential([\n",
    "    kb.Input(shape = [25]),\n",
    "    kb.layers.Dense(10), \n",
    "    kb.layers.Dense(5), # add relu here\n",
    "    kb.layers.Dense(2),\n",
    "    kb.layers.Dense(1, activation = \"sigmoid\")\n",
    "])\n",
    "\n",
    "activated_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try It Out\n",
    "Build a model with the following structure in 3 different ways:\n",
    "\n",
    "- input size of 9 \n",
    "- 2 hidden layers (with 7 and 3 nodes respectively) and `relu` activations\n",
    "- output layer with 1 node and a sigmoid activation\n",
    "\n",
    "1. Build the model using a basic `Sequential()` object and using `.add()` to add each layer. Set the activation(s) using an `Activation()` layer. \n",
    "2. Build the model using the Functional API method with `Model()`. Set the activation(s) using the `activation` argument in each layer where necessary. \n",
    "3. Build the model by subclassing `Model()`. Build all your layers in the `__init__()` method, and define a forward pass using your `call()` method. Then use the class to build your model. Set the activation(s) using the `activation` argument in each layer where necessary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. `Sequential()`\n",
    "\n",
    "my_model1 = kb.Sequential()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Functional API\n",
    "\n",
    "inputs = kb.Input(???)\n",
    "\n",
    "# stuff\n",
    "\n",
    "outputs = ???\n",
    "\n",
    "my_model2 = kb.Model(inputs = inputs, outputs = outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Subclass\n",
    "\n",
    "class MyModel(kb.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # layers\n",
    "        pass\n",
    "\n",
    "    def call(self, inputs):\n",
    "        pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "We've already used all these functions, but as a quick refresher:\n",
    "\n",
    "- `.summary()`: call it on a model to see the structure of the model as well as information about they layers\n",
    "- `.compile()`: tells python *how* to train your model, e.g. which optimizer to use, which metrics to collect, what your test/validation set is. \n",
    "- `.fit()`: train your model given the data (input and output), number of `epochs`, etc (just like sklearn but with more options)\n",
    "- `.predict()`: use your model to make predictions given some input values (just like sklearn)\n",
    "\n",
    "\n",
    "\n",
    "If you have time, download [this data set](https://www.kaggle.com/datasets/chaunguynnghunh/sepsis?select=Paitients_Files_Train.csv) and train one or all of the models you built on it (Don't include `ID` as a predictor). Don't forget to z-score and to use [`LabelBinarizer()`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelBinarizer.html) to change the outputs to 0's and 1's. Use whatever optimizer you want. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
